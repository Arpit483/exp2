addFaces.py

# import cv2
# import face_recognition
# import numpy as np
# import psycopg2
# import json

# # üìå Connect to the PostgreSQL Database
# conn = psycopg2.connect(
#     dbname="project",
#     user="postgres",
#     password="pratik115",
#     host="localhost",
#     port="5432"
# )
# cursor = conn.cursor()

# # üìå Get Student Name
# student_name = input("Enter the student's full name: ").strip()

# # üìå Capture Face from Webcam
# video_capture = cv2.VideoCapture(0)

# if not video_capture.isOpened():
#     print("Error: Could not open camera.")
#     video_capture.release()
#     exit()

# print("üì∏ Capturing face... Look at the camera.")
# face_encoding = None

# while True:
#     ret, frame = video_capture.read()
#     if not ret:
#         continue

#     # Convert frame to RGB
#     rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

#     # Detect face
#     face_locations = face_recognition.face_locations(rgb_frame)
#     face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)

#     if face_encodings:
#         face_encoding = face_encodings[0]
#         print("‚úÖ Face captured!")
#         break

#     cv2.imshow("Capture Face", frame)
#     if cv2.waitKey(1) & 0xFF == ord('q'):
#         print("‚ùå Face capture canceled.")
#         exit()

# video_capture.release()
# cv2.destroyAllWindows()

# # üìå Store Encoded Face in Database
# if face_encoding is not None:
#     face_encoding_list = face_encoding.tolist()
#     face_encoding_json = json.dumps(face_encoding_list)

#     cursor.execute("INSERT INTO faces (name, encoding) VALUES (%s, %s)", (student_name, face_encoding_json))
#     conn.commit()
#     print(f"‚úÖ {student_name}'s face added to the database!")

# cursor.close()
# conn.close()


# import cv2
# import face_recognition
# import numpy as np
# import psycopg2
# import json
# import pandas as pd
# import os

# # üìå Connect to the PostgreSQL Database
# conn = psycopg2.connect(
#     dbname="project",
#     user="postgres",
#     password="pratik115",
#     host="localhost",
#     port="5432"
# )
# cursor = conn.cursor()

# # üìå Get Student Name
# roll_number = input("Enter student's Roll No.: ").strip()
# student_name = input("Enter the student's full name: ").strip()

# # üìå Capture Face from Webcam
# video_capture = cv2.VideoCapture(0)

# if not video_capture.isOpened():
#     print("Error: Could not open camera.")
#     video_capture.release()
#     exit()

# print("üì∏ Capturing face... Look at the camera.")
# face_encoding = None

# while True:
#     ret, frame = video_capture.read()
#     if not ret:
#         continue

#     # Convert frame to RGB
#     rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

#     # Detect face
#     face_locations = face_recognition.face_locations(rgb_frame)
#     face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)

#     if face_encodings:
#         face_encoding = face_encodings[0]
#         print("‚úÖ Face captured!")
#         break

#     cv2.imshow("Capture Face", frame)
#     if cv2.waitKey(1) & 0xFF == ord('q'):
#         print("‚ùå Face capture canceled.")
#         exit()

# video_capture.release()
# cv2.destroyAllWindows()

# # üìå Store Encoded Face in Database
# if face_encoding is not None:
#     face_encoding_list = face_encoding.tolist()
#     face_encoding_json = json.dumps(face_encoding_list)

#     cursor.execute("INSERT INTO faces (name, encoding) VALUES (%s, %s)", (student_name, face_encoding_json))
#     conn.commit()
#     print(f"‚úÖ {student_name}'s face added to the database!")

# # üìå Update `students.xlsx`
# students_file = "students.xlsx"

# # Load existing student list or create new one
# if os.path.exists(students_file):
#     df_students = pd.read_excel(students_file, engine="openpyxl")
# else:
#     df_students = pd.DataFrame(columns=["Name"])

# # Ensure no duplicate entries
# if student_name not in df_students["Name"].values:
#     new_student = pd.DataFrame({"Name": [student_name]})
#     df_students = pd.concat([df_students, new_student], ignore_index=True)

#     # Save back to Excel
#     df_students.to_excel(students_file, index=False)
#     print(f"‚úÖ {student_name} added to {students_file}!")

# cursor.close()
# conn.close()




demo1.py


# import cv2
# import face_recognition
# import numpy as np
# import time
# import psycopg2
# import json
# import os
# import pandas as pd
# from datetime import datetime

# # Connect to PostgreSQL
# conn = psycopg2.connect(
#     dbname="project",
#     user="postgres",
#     password="pratik115",
#     host="localhost",
#     port="5432"
# )
# cursor = conn.cursor()

# # Create a table to store attendance records
# cursor.execute("""
# CREATE TABLE IF NOT EXISTS attendance (
#     id SERIAL PRIMARY KEY,
#     name TEXT NOT NULL,
#     timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP
              
               
# )
# """)
# conn.commit()

# # Load known faces from database
# known_faces = []
# known_names = []

# cursor.execute("SELECT name, encoding FROM faces")
# rows = cursor.fetchall()
# for name, encoding_str in rows:
#     encoding = np.array(json.loads(encoding_str), dtype=np.float32)  # Convert JSON back to NumPy array
#     known_faces.append(encoding)
#     known_names.append(name)

# print(f"‚úÖ Loaded {len(known_faces)} faces from database.")

# # Start webcam
# video_capture = cv2.VideoCapture(0)
# time.sleep(2)

# if not video_capture.isOpened():
#     print("Error: Could not open camera.")
#     video_capture.release()
#     exit()

# try:
#     while True:
#         ret, frame = video_capture.read()
#         if not ret:
#             continue  

#         small_frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)  # Reduce image size to speed up processing
#         rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)
        
#         face_locations = face_recognition.face_locations(rgb_small_frame)
#         face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations) if face_locations else []

#         for face_encoding, face_location in zip(face_encodings, face_locations):
#             matches = face_recognition.compare_faces(known_faces, face_encoding, tolerance=0.5)  # Adjust tolerance
#             name = "Unknown"

#             face_distances = face_recognition.face_distance(known_faces, face_encoding)
#             if len(face_distances) > 0:
#                 best_match_index = np.argmin(face_distances)
#                 if matches[best_match_index]:
#                     name = known_names[best_match_index]

#                     # ‚úÖ Store detected person's name in `attendance` table
#                     today = datetime.now().date()
#                     cursor.execute("SELECT * FROM attendance WHERE name = %s AND DATE(timestamp) = %s", (name, today))
#                     result = cursor.fetchone()

#                     if not result:  # If the person is not already marked today
#                         cursor.execute("INSERT INTO attendance (name) VALUES (%s)", (name,))
#                         conn.commit()
#                         print(f"üìå Attendance marked for: {name}")

#             # Draw rectangle around face
#             top, right, bottom, left = [v * 2 for v in face_location]  # Scale back after resizing
#             cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)
#             cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)

#         cv2.imshow('Face Recognition', frame)

#         if cv2.waitKey(1) & 0xFF == ord('q'):
#             break
# except Exception as e:
#     print(f"‚ùå Error: {e}")
# finally:
#     # video_capture.release()
#     # cv2.destroyAllWindows()
#     # cursor.close()
#     # conn.close()

#     query = "SELECT * FROM attendance;"
#     attendance_df = pd.read_sql(query, conn)

#     excel_filename = "attendance.xlsx"
#     attendance_df.to_excel(excel_filename, index=False)
#     print(f"üì§ Attendance data exported to {excel_filename}")

#     # Close resources
#     video_capture.release()
#     cv2.destroyAllWindows()
#     cursor.close()
#     conn.close()


# import cv2
# import face_recognition
# import numpy as np
# import time
# import psycopg2
# import json
# import pandas as pd
# from datetime import datetime

# # üìå Load Student Names from Excel
# students_file = "students.xlsx"
# df_students = pd.read_excel(students_file, engine="openpyxl")
# df_students.columns = df_students.columns.str.strip()  



# if "Attendance" not in df_students.columns:
#     df_students["Attendance"] = ""  

# conn = psycopg2.connect(
#     dbname="project",
#     user="postgres",
#     password="pratik115",
#     host="localhost",
#     port="5432"
# )
# cursor = conn.cursor()


# known_faces = []
# known_names = []

# cursor.execute("SELECT name, encoding FROM faces")
# rows = cursor.fetchall()
# for name, encoding_str in rows:
#     encoding = np.array(json.loads(encoding_str), dtype=np.float32)  
#     known_faces.append(encoding)
#     known_names.append(name)

# print(f"‚úÖ Loaded {len(known_faces)} faces from database.")


# video_capture = cv2.VideoCapture(0)
# time.sleep(2)

# if not video_capture.isOpened():
#     print("Error: Could not open camera.")
#     video_capture.release()
#     exit()


# present_students = set()

# try:
#     while True:
#         ret, frame = video_capture.read()
#         if not ret:
#             continue  

#         small_frame = cv2.resize(frame, (0, 0), fx=0.5, fy=0.5)  # Reduce image size to speed up processing
#         rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)
        
#         face_locations = face_recognition.face_locations(rgb_small_frame)
#         face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations) if face_locations else []

#         for face_encoding, face_location in zip(face_encodings, face_locations):
#             matches = face_recognition.compare_faces(known_faces, face_encoding, tolerance=0.5)  # Adjust tolerance
#             name = "Unknown"

#             face_distances = face_recognition.face_distance(known_faces, face_encoding)
#             if len(face_distances) > 0:
#                 best_match_index = np.argmin(face_distances)
#                 if matches[best_match_index]:
#                     name = known_names[best_match_index]
#                     present_students.add(name)  # Store recognized student name

#             # Draw rectangle around face
#             top, right, bottom, left = [v * 2 for v in face_location]  # Scale back after resizing
#             cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)
#             cv2.putText(frame, name, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)

#         cv2.imshow('Face Recognition', frame)

#         if cv2.waitKey(1) & 0xFF == ord('q'):
#             break

# except Exception as e:
#     print(f"‚ùå Error: {e}")

# finally:
  
#     df_students[datetime.now()] = df_students["Name"].apply(lambda x: "Present" if x in present_students else "Absent")

#     updated_filename = "attendance_updated.xlsx"


   
#     df_students.to_excel(updated_filename, index=False)
#     print(f"üì§ Attendance data exported to {updated_filename}")

    
#     video_capture.release()
#     cv2.destroyAllWindows()
#     cursor.close()
#     conn.close()


